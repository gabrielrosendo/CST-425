{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining â€“ Classification Part 1\n",
    "**Authors**\n",
    "### Eli Kaustinen and Gabriel Marcelino\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part I: Data Mining Techniques\n",
    "\n",
    "Explain each of the following data mining techniques in terms of how the algorithm works, its strengths, and weaknesses:\n",
    "\n",
    "### Classification: \n",
    "Classification algorithms categorize data into predefined labels or categories (like spam or not spam). They learn patterns from labeled training data and use that knowledge to classify new data. Common methods include decision trees, support vector machines (SVM), and neural networks. \n",
    "- Strengths: High accuracy with well-labeled data, useful for spam detection, medical diagnosis, and sentiment analysis.\n",
    "- Weaknesses: Performance drops with imbalanced or noisy data, and some models (e.g., deep learning) require significant computational resources.\n",
    "\n",
    "### Prediction\n",
    "Prediction models forecast future values based on historical data using regression techniques, time series analysis, or machine learning models.\n",
    "- Strengths: Useful for financial forecasting, sales predictions, and demand planning; can handle complex patterns.\n",
    "- Weaknesses: Accuracy depends on data quality and completeness, and it struggles with unpredictable external factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of each data mining functionality using a real-life data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spam Classification Results ===\n",
      "Model Accuracy: 98.84%\n",
      "\n",
      "Email content: Subject: naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Example email prediction: 0\n",
      "Actual label: 0\n",
      "=== House Price Prediction Results ===\n",
      "Feature names: MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
      "\n",
      "Last house features:\n",
      "MedInc: 3.5521\n",
      "HouseAge: 17.0000\n",
      "AveRooms: 3.9888\n",
      "AveBedrms: 1.0335\n",
      "Population: 1671.0000\n",
      "AveOccup: 3.7299\n",
      "Latitude: 34.2200\n",
      "Longitude: -118.3700\n",
      "\n",
      "Predicted price: $200940.25\n",
      "Actual price: $151500.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Part 1: Email Spam Classification\n",
    "with open('emails.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "df = df.dropna()\n",
    "X = df['Message']\n",
    "y = df['Label']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_transformed = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(\"\\n=== Spam Classification Results ===\")\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Example prediction\n",
    "example_email = X_test[0]\n",
    "predicted_label = model.predict([example_email])[0]\n",
    "print(\"Email content:\", X.iloc[0])\n",
    "print(f\"Example email prediction: {predicted_label}\")\n",
    "print(f\"Actual label: {y_test.iloc[0]}\")\n",
    "\n",
    "# Part 2: House Price Prediction\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"=== House Price Prediction Results ===\")\n",
    "print(\"Feature names:\", \", \".join(data.feature_names))\n",
    "print(\"\\nLast house features:\")\n",
    "for name, value in zip(data.feature_names, X_test[-1]):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "print(f\"\\nPredicted price: ${model.predict([X_test[-1]])[0]*100000:.2f}\")\n",
    "print(f\"Actual price: ${y_test[-1]*100000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convlusion\n",
    "\n",
    "Classification excels at categorizing data into discrete classes through methods like Naive Bayes, making it ideal for tasks like spam detection where clear categories exist. While powerful, classification can struggle with ambiguous cases and requires high-quality labeled training data. Prediction, as demonstrated through linear regression in housing price estimation, specializes in forecasting continuous numerical values by identifying underlying patterns and relationships in data. However, prediction models can be sensitive to outliers and may oversimplify complex relationships.\n",
    "\n",
    "## References\n",
    "\n",
    "https://www.geeksforgeeks.org/data-mining-techniques/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
